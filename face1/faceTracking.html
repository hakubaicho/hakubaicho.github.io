<!DOCTYPE html>
<html lang="ja">
  <head>
    <!-- 
      * 参考URL *
      表情認識で SNOW 的なアプリ
      https://kkblab.com/make/javascript/face.html

     -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>顔認識</title>
    <style>
      /* video 要素の上に canvas 要素をオーバーレイするための CSS */
      #container {              /* コンテナ用の div について */
        position: relative;     /* 座標指定を相対値指定にする */
      }
      #video {                  /* カメラ映像を流す video について */
        transform: scaleX(-1);  /* 左右反転させる */
      }
      #canvas {                 /* 描画用の canvas について */
        transform: scaleX(-1);  /* 左右反転させる */
        position: absolute;     /* 座標指定を絶対値指定にして */
        left: 0;                /* X座標を0に */
        top: 0;                 /* Y座標を0に */
      }
    </style>
  </head>
 
<body>
  <div id="container">  <!-- video の上に canvas をオーバーレイするための div 要素 -->
    <video id="video" width="800" height="600" autoplay></video>  <!-- カメラ映像を流す video -->
    <canvas id="canvas" width="800" height="600"></canvas>        <!-- 重ねて描画する canvas -->
  </div>
  <div id="dat"></div>  <!-- データ表示用 div 要素 -->
 
  <!-- clmtrackr 関連ファイルの読み込み -->
  <script src="clmtrackr.js"></script>          <!-- clmtrackr のメインライブラリの読み込み -->
  <script src="model_pca_20_svm.js"></script>   <!-- 顔モデル（※）の読み込み -->
  
  <script>
    // もろもろの準備
    var video = document.getElementById("video");           // video 要素を取得
    var canvas = document.getElementById("canvas");         // canvas 要素の取得
    var context = canvas.getContext("2d");                  // canvas の context の取得
    var stampNose = new Image();                            // ★鼻のスタンプ画像を入れる Image オブジェクト
    var stampEars = new Image();                            // ★耳のスタンプ画像を入れる Image オブジェクト
    var stampTshirt = new Image();                          // ★TShirtのスタンプ画像を入れる Image オブジェクト
    stampNose.src = "nose.png";                             // ★鼻のスタンプ画像のファイル名
    stampEars.src = "ears.png";                             // ★耳のスタンプ画像のファイル名
    stampTshirt.src = "tshirt_b.png";                         // ★耳のスタンプ画像のファイル名
    
    // getUserMedia によるカメラ映像の取得
    var media = navigator.mediaDevices.getUserMedia({       // メディアデバイスを取得
      video: {facingMode: "user"},                          // カメラの映像を使う（スマホならインカメラ）
      audio: false                                          // マイクの音声は使わない
    });
    media.then((stream) => {                                // メディアデバイスが取得できたら
      video.srcObject = stream;                             // video 要素にストリームを渡す
    });
    
    // clmtrackr の開始
    var tracker = new clm.tracker();  // tracker オブジェクトを作成
    tracker.init(pModel);             // tracker を所定のフェイスモデル（※）で初期化
    tracker.start(video);             // video 要素内でフェイストラッキング開始
    
    // 描画ループ
    function drawLoop() {
      requestAnimationFrame(drawLoop);                      // drawLoop 関数を繰り返し実行
      var positions = tracker.getCurrentPosition();         // 顔部品の現在位置の取得
      if(positions !== false)
      {
        // showData(positions);                                  // データの表示
        context.clearRect(0, 0, canvas.width, canvas.height); // canvas をクリア
        tracker.draw(canvas);                                 // canvas にトラッキング結果を描画
        
        drawStamp(positions, stampNose, 62, 2.5, 0.0, 0.0);     // ★鼻のスタンプを描画
        drawStamp(positions, stampEars, 33, 3.0, 0.0, -1.8);    // ★耳のスタンプを描画
        drawStampTShirt(positions, stampTshirt, 7, 9.0, 0.0, -1.8);  // ★TShirtのスタンプを描画
      }

    }
    drawLoop();                                             // drawLoop 関数をトリガー
    
    // 顔部品（特徴点）の位置データを表示する showData 関数
    function showData(pos) {
      var str = "";                                         // データの文字列を入れる変数
      for(var i = 0; i < pos.length; i++) {                 // 全ての特徴点（71個）について
        str += "特徴点" + i + ": ("
            + Math.round(pos[i][0]) + ", "                 // X座標（四捨五入して整数に）
            + Math.round(pos[i][1]) + ")<br>";             // Y座標（四捨五入して整数に）
      }
      var dat = document.getElementById("dat");             // データ表示用div要素の取得
      dat.innerHTML = str;                                  // データ文字列の表示
    }
    // ★スタンプを描く drawStamp 関数
    // (顔部品の位置データ, 画像, 基準位置, 大きさ, 横シフト, 縦シフト)
    function drawStamp(pos, img, bNo, scale, hShift, vShift) {
      var eyes = pos[32][0] - pos[27][0];                   // 幅の基準として両眼の間隔を求める
      var nose = pos[62][1] - pos[33][1];                   // 高さの基準として眉間と鼻先の間隔を求める
      var wScale = eyes / img.width;                        // 両眼の間隔をもとに画像のスケールを決める
      var imgW = img.width * scale * wScale;                // 画像の幅をスケーリング
      var imgH = img.height * scale * wScale;               // 画像の高さをスケーリング
      var imgL = pos[bNo][0] - imgW / 2 + eyes * hShift;    // 画像のLeftを決める
      var imgT = pos[bNo][1] - imgH / 2 + nose * vShift;    // 画像のTopを決める
      context.drawImage(img, imgL, imgT, imgW, imgH);       // 画像を描く
    }
    // ★スタンプを描く drawStamp 関数
    // (顔部品の位置データ, 画像, 基準位置, 大きさ, 横シフト, 縦シフト)
    function drawStampTShirt(pos, img, bNo, scale, hShift, vShift) {
      var eyes = pos[32][0] - pos[27][0];                   // 幅の基準として両眼の間隔を求める
      var nose = pos[62][1] - pos[33][1];                   // 高さの基準として眉間と鼻先の間隔を求める
      var wScale = eyes / img.width;                        // 両眼の間隔をもとに画像のスケールを決める

      var nose_top = pos[33][1];                            // 鼻の付け根
      var chin = pos[7][1];                                 // あごの先端

      var imgW = img.width * scale * wScale;                // 画像の幅をスケーリング
      var imgH = img.height * scale * wScale;               // 画像の高さをスケーリング
      var imgL = pos[bNo][0] - imgW / 2 + eyes * hShift;    // 画像のLeftを決める
      // var imgT = chin + ((chin-nose_top)/20);    // 画像のTopを決める
      var imgT = chin;    // 画像のTopを決める
      context.drawImage(img, imgL, imgT, imgW, imgH);       // 画像を描く
    }
    </script>
  </body>
</html>
